---
title: The good, the bad and the ugly in data imputation
author: goodfr
date: '2021-01-28'
slug: the-good-the-bad-and-the-ugly-in-data-imputation.en-us
thumbnailImage: /img/goodbadhed_inv.png
thumbnailImagePosition: left
coverImage: /img/goodbadhed_invrh.png
tags:
  - data science
  - Python
  - R
---

__photo credit : Clint Eastwood - The Good, The Bad and The Ugly__

<!-- output: -->
<!--   html_document: -->
<!--     code_folding: hide -->

<!--more-->

## Context

Missing values are a common issue when using real world data. If not dealt with, it can cause serious studies to be invalidated (as when [Thomas_Herndon](https://en.wikipedia.org/wiki/Thomas_Herndon) found out as a student that the "Growth in a Time of Debt" paper had errors, some caused by missing values). 

There are many strategies to handle missing values such as : 
* Omission (remove individuals or variables containing missing values)
* Recoding (replace all non-available values by a constant with eventually adding a dummy variable for missingness)
* Imputation (predict the missing values)

Often times we can see a re-coding question on Stack Overflow or a short mention of imputation on blog posts before handling the main work of machine learning. But rarely we will see a study on how fit is the method used to problem at hand. **As data cleaning and feature engineering, the process of choosing an acceptable strategy for non available values can be seen as time consuming and tiresome for data scientist.** This leads to systematic processing (0 re-coding and dummy variables or forest imputation) with little to no evaluation. 

Thus to proceed in more rigorous scientific way we need to determine a criteria (or metric) to determine what can be said to be a good strategy in missing values handling.


The study of missing values is in fact a whole research field with many sub-subject. 
* random missing values
* dependent missing values

## 3 data sets to test this methodology {.tabset}

To estimate strategies quality we need to control missingness. Thus we induce missing values in our data set.

### data_1

```{r}
# test
```

### data_2

### data_3


## Explore missingness {.tabset}

In some case we want to see if missing values follow a pattern. For this purpose the package `naniar` in R comes in handy :

```{r}

```

## Apply stategies {.tabset}

### Re-coding

### simple

### with dummies

### Imputation

## Evaluation of the strategies {.tabset}

### data_1

### data_2

### data_3

### Comparison of omiting vs the rest in an overall modeling process

## Take home message

With this pretentious titled post I learnt that missing are a research subject as a whole.

It can be challenging to assert which type of missing values is in a data set.

References :

* miss static website